{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "Let's see an example of how to run a logistic regression with Python and Spark! This is documentation example, we will quickly run through this and then show a more realistic example, afterwards, you will have another consulting project!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-2.2.0-bin-hadoop2.7')\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('logregdoc').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "training = spark.read.format(\"libsvm\").load(\"sample_libsvm_data.txt\")\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Fit the model\n",
    "lrModel = lr.fit(training)\n",
    "\n",
    "# Get the summary of the fitted model\n",
    "trainingSummary = lrModel.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|(692,[127,128,129...|[39.9727764450750...|[1.0,4.3655982185...|       0.0|\n",
      "|  1.0|(692,[158,159,160...|[-35.662380562160...|[3.25105944320044...|       1.0|\n",
      "|  1.0|(692,[124,125,126...|[-39.336799621156...|[8.24603148700906...|       1.0|\n",
      "|  1.0|(692,[152,153,154...|[-28.219286248176...|[5.55289803944932...|       1.0|\n",
      "|  1.0|(692,[151,152,153...|[-28.142070329444...|[5.99865861146384...|       1.0|\n",
      "|  0.0|(692,[129,130,131...|[37.8748140555402...|[1.0,3.5577649524...|       0.0|\n",
      "|  1.0|(692,[158,159,160...|[-36.610101257122...|[1.26018713626709...|       1.0|\n",
      "|  1.0|(692,[99,100,101,...|[-29.504314986871...|[1.53616833535573...|       1.0|\n",
      "|  0.0|(692,[154,155,156...|[13.6899025280154...|[0.99999886616363...|       0.0|\n",
      "|  0.0|(692,[127,128,129...|[33.3183003583946...|[0.99999999999999...|       0.0|\n",
      "|  1.0|(692,[154,155,156...|[-38.890745680172...|[1.28814203951267...|       1.0|\n",
      "|  0.0|(692,[153,154,155...|[67.0874697775197...|[1.0,7.3161410668...|       0.0|\n",
      "|  0.0|(692,[151,152,153...|[73.6044717083260...|[1.0,1.0813943437...|       0.0|\n",
      "|  1.0|(692,[129,130,131...|[-36.334297811539...|[1.66040853309745...|       1.0|\n",
      "|  0.0|(692,[154,155,156...|[50.8305653519066...|[1.0,8.4055465116...|       0.0|\n",
      "|  1.0|(692,[150,151,152...|[-37.436601496257...|[5.51430202129915...|       1.0|\n",
      "|  0.0|(692,[124,125,126...|[52.0845325408060...|[1.0,2.3986944209...|       0.0|\n",
      "|  0.0|(692,[152,153,154...|[46.0777337354325...|[1.0,9.7430403263...|       0.0|\n",
      "|  1.0|(692,[97,98,99,12...|[-21.968532477749...|[2.87864141487992...|       1.0|\n",
      "|  1.0|(692,[124,125,126...|[-31.127071144794...|[3.03168980995190...|       1.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainingSummary.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# May change soon!\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate predictionAndLabels for Evaluaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.ml.classification.BinaryLogisticRegressionSummary at 0x7fbbbac810f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrModel.evaluate(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usually would do this on a separate test set!\n",
    "predictionAndLabels = lrModel.evaluate(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|(692,[127,128,129...|[39.9727764450750...|[1.0,4.3655982185...|       0.0|\n",
      "|  1.0|(692,[158,159,160...|[-35.662380562160...|[3.25105944320044...|       1.0|\n",
      "|  1.0|(692,[124,125,126...|[-39.336799621156...|[8.24603148700906...|       1.0|\n",
      "|  1.0|(692,[152,153,154...|[-28.219286248176...|[5.55289803944932...|       1.0|\n",
      "|  1.0|(692,[151,152,153...|[-28.142070329444...|[5.99865861146384...|       1.0|\n",
      "|  0.0|(692,[129,130,131...|[37.8748140555402...|[1.0,3.5577649524...|       0.0|\n",
      "|  1.0|(692,[158,159,160...|[-36.610101257122...|[1.26018713626709...|       1.0|\n",
      "|  1.0|(692,[99,100,101,...|[-29.504314986871...|[1.53616833535573...|       1.0|\n",
      "|  0.0|(692,[154,155,156...|[13.6899025280154...|[0.99999886616363...|       0.0|\n",
      "|  0.0|(692,[127,128,129...|[33.3183003583946...|[0.99999999999999...|       0.0|\n",
      "|  1.0|(692,[154,155,156...|[-38.890745680172...|[1.28814203951267...|       1.0|\n",
      "|  0.0|(692,[153,154,155...|[67.0874697775197...|[1.0,7.3161410668...|       0.0|\n",
      "|  0.0|(692,[151,152,153...|[73.6044717083260...|[1.0,1.0813943437...|       0.0|\n",
      "|  1.0|(692,[129,130,131...|[-36.334297811539...|[1.66040853309745...|       1.0|\n",
      "|  0.0|(692,[154,155,156...|[50.8305653519066...|[1.0,8.4055465116...|       0.0|\n",
      "|  1.0|(692,[150,151,152...|[-37.436601496257...|[5.51430202129915...|       1.0|\n",
      "|  0.0|(692,[124,125,126...|[52.0845325408060...|[1.0,2.3986944209...|       0.0|\n",
      "|  0.0|(692,[152,153,154...|[46.0777337354325...|[1.0,9.7430403263...|       0.0|\n",
      "|  1.0|(692,[97,98,99,12...|[-21.968532477749...|[2.87864141487992...|       1.0|\n",
      "|  1.0|(692,[124,125,126...|[-31.127071144794...|[3.03168980995190...|       1.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictionAndLabels.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionAndLabels = predictionAndLabels.predictions.select('label','prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|label|prediction|\n",
      "+-----+----------+\n",
      "|  0.0|       0.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  0.0|       0.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  1.0|       1.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  1.0|       1.0|\n",
      "|  0.0|       0.0|\n",
      "|  1.0|       1.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictionAndLabels.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluators\n",
    "\n",
    "Evaluators will be a very important part of our pipline when working with Machine Learning, let's see some basics for Logistic Regression, useful links:\n",
    "\n",
    "https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.evaluation.BinaryClassificationEvaluator\n",
    "\n",
    "https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.evaluation.MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For multiclass\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label',\n",
    "                                             metricName='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = evaluator.evaluate(predictionAndLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay let's move on see some more examples!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
